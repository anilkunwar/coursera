{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huber Loss hyperparameter and class\n",
    "\n",
    "> In this post, we'll extend our previous Huber loss function and show how you can include hyperparameters in defining loss functions. We'll also look at how to implement a custom loss as an object by inheriting the [Loss](https://www.tensorflow.org/api_docs/python/tf/keras/losses/Loss) class. This is the summary of lecture \"Custom Models, Layers and Loss functions with Tensorflow\" from DeepLearning.AI.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Chanseok Kang\n",
    "- categories: [Python, Coursera, Tensorflow, DeepLearining.AI]\n",
    "- image: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data\n",
    "\n",
    "As before, this model will be trained on the `xs` and `ys` below where the relationship is $y = 2x-1$. Thus, later, when we test for `x=10`, whichever version of the model gets the closest answer to `19` will be deemed more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "\n",
    "# labels\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(xs, ys);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom loss with hyperparameter\n",
    "\n",
    "The `loss` argument in `model.compile()` only accepts functions that accepts two parameters: the ground truth (`y_true`) and the model predictions (`y_pred`). If we want to include a hyperparameter that we can tune, then we can define a wrapper function that accepts this hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function that accepts the hyperparamter\n",
    "def my_huber_loss_with_threshold(threshold):\n",
    "    # function that accepts the ground truth and predictions\n",
    "    def my_huber_loss(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) <= threshold\n",
    "        small_error_loss = tf.square(error) / 2\n",
    "        big_error_loss = threshold * (tf.abs(error) - (threshold / 2))\n",
    "        return tf.where(is_small_error, small_error_loss, big_error_loss)\n",
    "    \n",
    "    # return the inner function tuned by the hyperparameter\n",
    "    return my_huber_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now specify the `loss` as the wrapper function above. Notice that we can now set the `threshold` value. Try varying this value and see the results you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7dc3868550>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=1, input_shape=[1,])\n",
    "])\n",
    "\n",
    "model.compile(optimizer='sgd', loss=my_huber_loss_with_threshold(threshold=1.2))\n",
    "model.fit(xs, ys, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18.604269]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([10.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Custom Loss as a Class\n",
    "\n",
    "We can also implement our custom loss as a class. It inherits from the Keras Loss class and the syntax and required methods are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import Loss\n",
    "\n",
    "class MyHuberLoss(Loss):\n",
    "    # Initialize instance attributes\n",
    "    def __init__(self, threshold=1):\n",
    "        super().__init__()\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    # Compute Loss\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) <= self.threshold\n",
    "        small_error_loss = tf.square(error) / 2\n",
    "        big_error_loss = self.threshold * (tf.abs(error) - self.threshold / 2)\n",
    "        return tf.where(is_small_error, small_error_loss, big_error_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can specify the loss by instantiating an object from your custom loss class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7dc0312250>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=1, input_shape=[1,])\n",
    "])\n",
    "\n",
    "model.compile(optimizer='sgd', loss=MyHuberLoss(threshold=1.02))\n",
    "model.fit(xs, ys, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18.334595]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([10.0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
