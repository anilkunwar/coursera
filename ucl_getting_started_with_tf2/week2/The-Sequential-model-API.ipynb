{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Sequential Model API\n",
    "\n",
    "> In this post, we will dig into the basic usage of building neural network with Tensorflow Sequential APIs.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Chanseok Kang\n",
    "- categories: [Python, Deep_Learning, Tensorflow-Keras]\n",
    "- image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy: 1.18.1\n",
      "Pandas: 1.0.1\n",
      "Tensorflow: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(\"NumPy: {}\".format(np.__version__))\n",
    "print(\"Pandas: {}\".format(pd.__version__))\n",
    "print(\"Tensorflow: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a sequential model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding Tutorial - Build a feedforward neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Sequential feedforward neural network model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(784, 16) dtype=float32, numpy=\n",
       " array([[ 0.05694753, -0.01445955,  0.02889278, ...,  0.07327136,\n",
       "         -0.07537139,  0.08616881],\n",
       "        [-0.07410051, -0.03694982, -0.04157752, ...,  0.03010982,\n",
       "         -0.02780097, -0.00887114],\n",
       "        [ 0.07740739,  0.04293187,  0.01681171, ...,  0.08571155,\n",
       "          0.01035317, -0.05937039],\n",
       "        ...,\n",
       "        [ 0.05397604,  0.07120949,  0.08604382, ..., -0.05617909,\n",
       "         -0.03425014, -0.08230225],\n",
       "        [ 0.02035844, -0.06967027,  0.01005485, ...,  0.02447511,\n",
       "          0.07991299, -0.00553514],\n",
       "        [ 0.00868416,  0.05871408, -0.07087392, ...,  0.02097424,\n",
       "         -0.03808666,  0.03541996]], dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(16,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(16, 16) dtype=float32, numpy=\n",
       " array([[-0.29837987, -0.34982526,  0.07724884, -0.4041955 ,  0.33830157,\n",
       "         -0.34303218, -0.33311543, -0.3687417 ,  0.3053688 , -0.4259578 ,\n",
       "          0.05160168, -0.07745048,  0.01009619, -0.38661185, -0.2695833 ,\n",
       "          0.22177586],\n",
       "        [ 0.19337997,  0.39986816, -0.34199524, -0.22212602, -0.19602872,\n",
       "          0.33394143,  0.08892348, -0.4304812 , -0.39904565, -0.01082432,\n",
       "         -0.2171008 , -0.28054196, -0.18045801,  0.34201166, -0.14762163,\n",
       "         -0.15545681],\n",
       "        [ 0.02793452, -0.26505166, -0.05865431, -0.04089031,  0.41515753,\n",
       "         -0.00056419, -0.12148583,  0.13455799, -0.1378997 ,  0.03870618,\n",
       "          0.1043615 ,  0.3009735 ,  0.42573974,  0.27767596,  0.16099915,\n",
       "          0.3383269 ],\n",
       "        [ 0.41700062,  0.008279  , -0.11232623, -0.17138916,  0.4113665 ,\n",
       "         -0.31607234, -0.0218671 , -0.14520627,  0.3396589 ,  0.1722584 ,\n",
       "          0.39770272, -0.397169  ,  0.12631938, -0.19557366,  0.16796854,\n",
       "          0.16926411],\n",
       "        [ 0.29289278,  0.21162656, -0.32874534, -0.38346544, -0.10605514,\n",
       "         -0.29687113, -0.01339754,  0.14092943,  0.05497488, -0.09319577,\n",
       "          0.17334488, -0.36374962,  0.35367116, -0.02378249, -0.32206562,\n",
       "          0.39195928],\n",
       "        [-0.02747265, -0.24009733,  0.08137569, -0.02197871,  0.26853433,\n",
       "         -0.01128343, -0.26911905, -0.14048612, -0.08504149, -0.12753737,\n",
       "          0.1884875 , -0.07564145,  0.3275459 , -0.14642572,  0.11756125,\n",
       "         -0.16974807],\n",
       "        [-0.06533837,  0.14773199,  0.12024048, -0.29191086,  0.0921661 ,\n",
       "          0.28412166,  0.26235208, -0.05042881, -0.12040091,  0.05661154,\n",
       "          0.403711  , -0.18650293,  0.37330368, -0.1203213 , -0.0734598 ,\n",
       "         -0.03701103],\n",
       "        [-0.08044779,  0.18317702,  0.32705048,  0.2187582 ,  0.34885576,\n",
       "         -0.4260088 , -0.04791185, -0.18427423,  0.18371728, -0.07873395,\n",
       "          0.07330236, -0.01414302, -0.3321709 , -0.31176904, -0.01195085,\n",
       "          0.09308532],\n",
       "        [-0.1295633 , -0.39326638,  0.0086399 ,  0.17204306, -0.34362012,\n",
       "          0.17726043,  0.41988286,  0.30208954, -0.23176362,  0.10266027,\n",
       "         -0.24446182, -0.1224502 ,  0.2759522 , -0.28086138, -0.28831702,\n",
       "         -0.25067586],\n",
       "        [-0.17366236, -0.27322358,  0.12591174,  0.31976947, -0.16721275,\n",
       "          0.14916113, -0.37078345,  0.38906357, -0.26809698, -0.01198441,\n",
       "          0.38171914,  0.27549765,  0.08747098, -0.2322668 , -0.3137472 ,\n",
       "         -0.35503268],\n",
       "        [ 0.36651185, -0.22423694, -0.07205752, -0.32146528, -0.32459164,\n",
       "          0.33809128,  0.25558773,  0.12474826, -0.3276762 ,  0.25497362,\n",
       "         -0.34845507, -0.23548134,  0.23566046,  0.17119798,  0.39320132,\n",
       "          0.00409958],\n",
       "        [ 0.136475  , -0.37230858, -0.4253389 ,  0.06666249,  0.27179012,\n",
       "          0.22680774, -0.37961704, -0.27411765,  0.21133801,  0.28648505,\n",
       "         -0.13860172, -0.40183514, -0.25276685, -0.10883069, -0.3483089 ,\n",
       "          0.1771284 ],\n",
       "        [ 0.37134907,  0.3018804 , -0.3225879 ,  0.21986583,  0.09862289,\n",
       "         -0.41421992, -0.28533396, -0.05254942, -0.26369596, -0.20358607,\n",
       "          0.2718816 ,  0.02993816,  0.3068495 , -0.4063185 , -0.10471168,\n",
       "         -0.20918582],\n",
       "        [ 0.19580904,  0.07260147,  0.08417842,  0.09127608, -0.20025778,\n",
       "         -0.31160563, -0.25286862, -0.39806396,  0.30205843,  0.24891606,\n",
       "         -0.4113981 ,  0.23441693, -0.30594516, -0.2597825 ,  0.40485498,\n",
       "         -0.13599867],\n",
       "        [-0.18592995, -0.41568622, -0.1109226 , -0.3538212 ,  0.02406803,\n",
       "         -0.3021618 , -0.16894281, -0.347716  ,  0.03417981,  0.1664274 ,\n",
       "          0.3269302 , -0.35941982, -0.14900866,  0.09789225,  0.21962103,\n",
       "          0.340888  ],\n",
       "        [-0.39742255, -0.32051766, -0.07833946, -0.22384916,  0.43096754,\n",
       "          0.1707873 ,  0.18614098, -0.3128926 , -0.24646579, -0.38320538,\n",
       "         -0.03271827, -0.35368213, -0.09692886, -0.11395544, -0.40488616,\n",
       "          0.21627471]], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(16,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_2/kernel:0' shape=(16, 16) dtype=float32, numpy=\n",
       " array([[-0.15521348, -0.07879588, -0.24848811,  0.3253369 ,  0.19245264,\n",
       "         -0.15593594,  0.17115894,  0.26279417, -0.2777354 ,  0.39367977,\n",
       "          0.07168022, -0.11165881, -0.32216132, -0.26085752,  0.17860106,\n",
       "         -0.39997035],\n",
       "        [ 0.4093474 ,  0.09661266, -0.11834276,  0.39808318, -0.32379568,\n",
       "         -0.4168587 , -0.16748726,  0.07075712, -0.20498846, -0.4013775 ,\n",
       "         -0.20829065, -0.06795111, -0.19186027, -0.09336942, -0.25136536,\n",
       "         -0.41769937],\n",
       "        [ 0.12428197, -0.13540867,  0.13121638, -0.34620428, -0.04142466,\n",
       "         -0.23640521, -0.2767113 ,  0.29059735,  0.12994632, -0.30420065,\n",
       "          0.37335965,  0.27657112,  0.2667174 , -0.21456537, -0.32903296,\n",
       "         -0.19917491],\n",
       "        [-0.18824746, -0.37965038, -0.00996774, -0.40295744, -0.20351608,\n",
       "         -0.4123863 ,  0.137826  ,  0.3723928 ,  0.31973293,  0.12956342,\n",
       "          0.16676882,  0.11495861, -0.17160079,  0.20422128, -0.10259274,\n",
       "          0.40096632],\n",
       "        [ 0.30886188,  0.06140015,  0.15643564, -0.2541901 , -0.38942724,\n",
       "          0.21111843, -0.4110337 ,  0.12251267, -0.37615258, -0.43286446,\n",
       "         -0.05224198, -0.400096  , -0.11787292,  0.2349157 , -0.16585743,\n",
       "          0.30548492],\n",
       "        [ 0.3678176 , -0.28824487,  0.06730828, -0.37630236,  0.2948254 ,\n",
       "         -0.18450527, -0.36293268,  0.01493043,  0.40840366, -0.29946253,\n",
       "         -0.17362487, -0.3011706 , -0.08176151,  0.14392987, -0.1428602 ,\n",
       "         -0.01319301],\n",
       "        [-0.12539217, -0.11481202,  0.22422805,  0.30193093, -0.25357178,\n",
       "          0.04471415,  0.03779987,  0.31789884, -0.35060936, -0.0358437 ,\n",
       "         -0.2997386 , -0.35634154,  0.3343579 ,  0.03339469, -0.10031074,\n",
       "         -0.2669813 ],\n",
       "        [ 0.26011834, -0.00129256,  0.10309765, -0.29113802,  0.07687935,\n",
       "         -0.11097422, -0.20210202, -0.30347645, -0.21688554,  0.04857081,\n",
       "         -0.39653346,  0.11668888,  0.04900059, -0.15030944,  0.42393115,\n",
       "         -0.12129515],\n",
       "        [-0.42016676, -0.03204361,  0.11118647,  0.28594717, -0.28754884,\n",
       "         -0.05457929, -0.39948007,  0.12288186, -0.12037283,  0.13181517,\n",
       "          0.14204118, -0.10549021,  0.3285785 , -0.14957348,  0.189868  ,\n",
       "         -0.24994904],\n",
       "        [ 0.22965333, -0.01075649,  0.03320318,  0.13492599,  0.15371963,\n",
       "         -0.23266138, -0.19925678, -0.05220595,  0.12172547,  0.03977451,\n",
       "          0.1905028 ,  0.14742044, -0.0481396 , -0.37584707,  0.31613293,\n",
       "          0.31140265],\n",
       "        [ 0.22170338,  0.15528587,  0.19454125, -0.00433126,  0.14696237,\n",
       "          0.18970165, -0.0930469 ,  0.31174502,  0.02920932, -0.00204155,\n",
       "         -0.1822907 ,  0.3078945 ,  0.2454113 ,  0.42800483, -0.19562785,\n",
       "          0.02668607],\n",
       "        [-0.13345096, -0.35354978,  0.1134406 ,  0.23587313, -0.363778  ,\n",
       "          0.421752  , -0.2561235 ,  0.3447186 , -0.22309843, -0.10556474,\n",
       "          0.35497198, -0.28246695, -0.02074778, -0.00056276,  0.35461274,\n",
       "          0.14605519],\n",
       "        [-0.3457172 , -0.424724  ,  0.1993365 ,  0.12069377, -0.07489616,\n",
       "          0.00153908, -0.18060502,  0.04317477, -0.3624359 , -0.30760503,\n",
       "         -0.3971153 ,  0.00243631, -0.11386293, -0.2767685 , -0.4181685 ,\n",
       "         -0.3502023 ],\n",
       "        [-0.30914772, -0.40442157, -0.06714731,  0.23520806,  0.22102764,\n",
       "         -0.1107215 ,  0.35388365,  0.19486234,  0.24993482,  0.3980578 ,\n",
       "         -0.10960704,  0.1161097 , -0.06025481, -0.22082326,  0.2538977 ,\n",
       "          0.41409406],\n",
       "        [-0.24841163, -0.14078355,  0.27960142, -0.1696558 , -0.36390913,\n",
       "          0.25809225, -0.36656082, -0.1579209 , -0.23292805, -0.41554457,\n",
       "         -0.03323653,  0.3584312 ,  0.20672604, -0.3969593 , -0.08094481,\n",
       "         -0.10587713],\n",
       "        [ 0.29421625, -0.40503305,  0.08241954, -0.13964587, -0.3712222 ,\n",
       "          0.00785291, -0.32368636, -0.21088554,  0.0814546 , -0.18855377,\n",
       "         -0.02988902,  0.23024705,  0.20386669,  0.2474232 , -0.30594105,\n",
       "          0.01416606]], dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(16,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the model init weights\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 13,104\n",
      "Trainable params: 13,104\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional and pooling layers\n",
    "### Coding Tutorial - Build Convolutional Neural network model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Sequential convolutional neural network model\n",
    "model = Sequential([\n",
    "    Conv2D(16, (3, 3), padding='SAME', strides=2, activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((3, 3)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 14, 14, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 17,258\n",
      "Trainable params: 17,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the default tensorflow data type is 'channels_last', but we can change it with `data_format` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 16, 14, 14)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 4, 4)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 17,258\n",
      "Trainable params: 17,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(16, (3, 3), padding='SAME', strides=2, activation='relu', input_shape=(1, 28, 28), data_format='channels_first'),\n",
    "    MaxPooling2D((3, 3), data_format='channels_first'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight and bias initialisers \n",
    "\n",
    "In this reading, we investigate different ways to initialise weights and biases in the layers of neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default weights and biases\n",
    "\n",
    "In the models we have worked with so far, we have not specified the initial values of the weights and biases in each layer of our neural networks.\n",
    "\n",
    "The default values of the weights and biases in TensorFlow depend on the type of layers we are using. \n",
    "\n",
    "For example, in a `Dense` layer, the biases are set to zero (`zeros`) by default, while the weights are set according to `glorot_uniform`, the Glorot uniform initialiser. \n",
    "\n",
    "The Glorot uniform initialiser draws the weights uniformly at random from the closed interval $[-c,c]$, where $$c = \\sqrt{\\frac{6}{n_{input}+n_{output}}}$$\n",
    "\n",
    "and $n_{input}$ and $n_{output}$ are the number of inputs to, and outputs from the layer respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising your own weights and biases\n",
    "We often would like to initialise our own weights and biases, and TensorFlow makes this process quite straightforward.\n",
    "\n",
    "When we construct a model in TensorFlow, each layer has optional arguments `kernel_initialiser` and `bias_initialiser`, which are used to set the weights and biases respectively.\n",
    "\n",
    "If a layer has no weights or biases (e.g. it is a max pooling layer), then trying to set either `kernel_initialiser` or `bias_initialiser` will throw an error.\n",
    "\n",
    "Let's see an example, which uses some of the different initialisations available in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv1D, MaxPooling1D\n",
    "\n",
    "# Construct a model\n",
    "model = Sequential([\n",
    "    Conv1D(filters=16, kernel_size=3, input_shape=(128, 64), kernel_initializer='random_uniform',\n",
    "           bias_initializer='zeros', activation='relu'),\n",
    "    MaxPooling1D(pool_size=4),\n",
    "    Flatten(),\n",
    "    Dense(64, kernel_initializer='he_uniform', bias_initializer='ones', activation='relu')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the following example illustrates, we can also instantiate initialisers in a slightly different manner, allowing us to set optional arguments of the initialisation method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The compile method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model optimizer, loss function and metrics\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse_categorical_crossentropy\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000018A58805648>\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Print the resulting model attributes\n",
    "print(model.loss)\n",
    "print(model.optimizer)\n",
    "print(model.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can implement it like this,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical_crossentropy\n",
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000018A586ECF08>\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.005>\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
    "acc = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "mae = tf.keras.metrics.MeanAbsoluteError()\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[acc, mae])\n",
    "\n",
    "print(model.loss)\n",
    "print(model.optimizer)\n",
    "print(model.optimizer.lr)\n",
    "print(model.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics in tf.Keras\n",
    "In this reading we will be exploring the different metrics in Keras that may be used to judge the performance of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most common metrics used for classification problems in Keras is `'accuracy'`. \n",
    "\n",
    "We will begin with a simple example of a model that uses accuracy as a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential([\n",
    "  Flatten(input_shape=(28,28)),\n",
    "  Dense(32, activation='relu'),\n",
    "  Dense(32, activation='tanh'),\n",
    "  Dense(10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a model that uses accuracy as a metric to judge its performance.\n",
    "\n",
    "But how is this metric actually calculated? We will break our discussion into two cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 1 - Binary Classification with sigmoid activation function\n",
    "Suppose we are training a model for a binary classification problem with a sigmoid activation function (softmax activation functions are covered in the next case). \n",
    "\n",
    "Given a training example with input $x^{(i)}$, the model will output a float between 0 and 1. Based on whether this float is less than or greater than our \"threshold\" (which by default is set at 0.5), we round the float to get the predicted classification $y_{pred}$ from the model.\n",
    "\n",
    "The accuracy metric compares the value of $y_{pred}$ on each training example with the true output, the one-hot coded vector $y_{true}^{(i)}$ from our training data.\n",
    "\n",
    "Let $$\\delta(y_{pred}^{(i)},y_{true}^{(i)}) = \\begin{cases} 1 & y_{pred}=y_{true}\\\\\n",
    "0 & y_{pred}\\neq y_{true} \\end{cases}$$\n",
    "\n",
    "The accuracy metric  computes the mean of $\\delta(y_{pred}^{(i)},y_{true}^{(i)})$ over all training examples.\n",
    "\n",
    "$$ accuracy = \\frac{1}{N} \\sum_{i=1}^N \\delta(y_{pred}^{(i)},y_{true}^{(i)}) $$\n",
    "\n",
    "This is implemented in the backend of Keras as follows. \n",
    "Note: We have set $y_{true}$ and $y_{pred}$ ourselves for the purposes of this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.6666667>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sigmoid activation function\n",
    "y_true = tf.constant([0.0,1.0,1.0])\n",
    "y_pred = tf.constant([0.4,0.8, 0.3])\n",
    "accuracy = K.mean(K.equal(y_true, K.round(y_pred)))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 2 - Categorical Classification\n",
    "\n",
    "Now suppose we are training a model for a classification problem which should sort data into $m>2$ different classes using a softmax activation function in the last layer.\n",
    "\n",
    "Given a training example with input $x^{(i)}$, the model will output a tensor of probabilities $p_1, p_2, \\dots p_m$, giving the likelihood (according to the model) that $x^{(i)}$ falls into each class.\n",
    "\n",
    "The accuracy metric works by determining the largest argument in the $y_{pred}^{(i)}$ tensor, and compares its index to the index of the maximum value of $y_{true}^{(i)}$ to determine $\\delta(y_{pred}^{(i)},y_{true}^{(i)})$. It then computes the accuracy in the same way as for the binary classification case.\n",
    "\n",
    "$$ accuracy = \\frac{1}{N} \\sum_{i=1}^N \\delta(y_{pred}^{(i)},y_{true}^{(i)}) $$\n",
    "\n",
    "In the backend of Keras, the accuracy metric is implemented slightly differently depending on whether we have a binary classification problem ($m=2$) or a categorical classifcation problem. Note that the accuracy for binary classification problems is the same, no matter if we use a sigmoid or softmax activation function to obtain the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binary classification with softmax\n",
    "y_true = tf.constant([[0.0,1.0],[1.0,0.0],[1.0,0.0],[0.0,1.0]])\n",
    "y_pred = tf.constant([[0.4,0.6], [0.3,0.7], [0.05,0.95],[0.33,0.67]])\n",
    "accuracy =K.mean(K.equal(y_true, K.round(y_pred)))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.6666667>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categorical classification with m>2\n",
    "y_true = tf.constant([[0.0,1.0,0.0,0.0],[1.0,0.0,0.0,0.0],[0.0,0.0,1.0,0.0]])\n",
    "y_pred = tf.constant([[0.4,0.6,0.0,0.0], [0.3,0.2,0.1,0.4], [0.05,0.35,0.5,0.1]])\n",
    "accuracy = K.mean(K.equal(K.argmax(y_true, axis=-1), K.argmax(y_pred, axis=-1)))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other examples of metrics\n",
    "We will now look at some other metrics in Keras. A full list is available at <https://keras.io/metrics/>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary accuracy and categorical accuracy\n",
    "The `binary_accuracy` and `categorical_accuracy` metrics are, by default, identical to the Case 1 and 2 respectively of the `accuracy` metric explained above. \n",
    "\n",
    "However, using `binary_accuracy` allows you to use the optional `threshold` argument, which sets the minimum value of $y_{pred}$ which will be rounded to 1. As mentioned above, it is set as `threshold=0.5` by default.\n",
    "\n",
    "Below we give some examples of how to compile a model with `binary_accuracy` with and without a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with default threshold (=0.5)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The threshold can be specified as follows\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparse categorical accuracy\n",
    "\n",
    "This is a very similar metric to categorical accuracy with one major difference - the label $y_{true}$ of each training example is not expected to be a one-hot encoded vector, but to be a tensor consisting of a single integer. This integer is then compared to the index of the maximum argument of $y_{pred}$ to determine $\\delta(y_{pred}^{(i)},y_{true}^{(i)})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two examples of compiling a model with a sparse categorical accuracy metric\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[\"sparse_categorical_accuracy\"])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Sparse) Top $k$-categorical accuracy \n",
    "In top $k$-categorical accuracy, instead of computing how often the model correctly predicts the label of a training example, the metric computes how often the model has $y_{true}$ in the top $k$ of its predictions. By default, $k=5$.\n",
    "\n",
    "As before, the main difference between top $k$-categorical accuracy and its sparse version is that the former assumes $y_{true}$ is a one-hot encoded vector, whereas the sparse version assumes $y_{true}$ is an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile a model with a top-k categorical accuracy metric with default k (=5)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[\"top_k_categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify k instead with the sparse top-k categorical accuracy\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.SparseTopKCategoricalAccuracy(k=3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom metrics\n",
    "It is also possible to define your own custom metric in Keras.\n",
    "You will need to make sure that your metric takes in (at least) two arguments called `y_true` and `y_pred` and then output a single tensor value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom metric\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use this metric when we compile our model as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify k instead with the sparse top-k categorical accuracy\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[mean_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple metrics\n",
    "Finally, it is possible to use multiple metrics to judge the performance of your model. \n",
    "\n",
    "Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with multiple metrics\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[mean_pred, \"accuracy\",tf.keras.metrics.SparseTopKCategoricalAccuracy(k=3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources and Further Reading\n",
    "* The metrics page on the Keras website: https://keras.io/metrics/\n",
    "* The source code for the metrics: https://github.com/keras-team/keras/blob/master/keras/metrics.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The fit method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Fashion-MNIST dataset\n",
    "fashion_mnist_data = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist_data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the training data\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Ankle boot\n"
     ]
    }
   ],
   "source": [
    "# Define the labels\n",
    "labels = [\n",
    "    'T-shirt/top',\n",
    "    'Trouser',\n",
    "    'Pullover',\n",
    "    'Dress',\n",
    "    'Coat',\n",
    "    'Sandal',\n",
    "    'Shirt',\n",
    "    'Sneaker',\n",
    "    'Bag',\n",
    "    'Ankle boot'\n",
    "]\n",
    "\n",
    "print(train_labels[0])\n",
    "print(labels[train_labels[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale the image values so that they lie in between 0 and 1.\n",
    "train_images = train_images / 255.\n",
    "test_images = test_images/ 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display one of the images\n",
    "sample = train_images[0, :, :]\n",
    "plt.imshow(sample)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 10,410\n",
      "Trainable params: 10,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((3, 3)),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
    "acc = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "mae = tf.keras.metrics.MeanAbsoluteError()\n",
    "\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy',\n",
    "              metrics=[acc, mae])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "235/235 - 1s - loss: 0.5683 - sparse_categorical_accuracy: 0.8006 - mean_absolute_error: 4.4200\n",
      "Epoch 2/8\n",
      "235/235 - 1s - loss: 0.3939 - sparse_categorical_accuracy: 0.8602 - mean_absolute_error: 4.4200\n",
      "Epoch 3/8\n",
      "235/235 - 1s - loss: 0.3585 - sparse_categorical_accuracy: 0.8732 - mean_absolute_error: 4.4200\n",
      "Epoch 4/8\n",
      "235/235 - 1s - loss: 0.3405 - sparse_categorical_accuracy: 0.8788 - mean_absolute_error: 4.4200\n",
      "Epoch 5/8\n",
      "235/235 - 1s - loss: 0.3290 - sparse_categorical_accuracy: 0.8827 - mean_absolute_error: 4.4200\n",
      "Epoch 6/8\n",
      "235/235 - 1s - loss: 0.3152 - sparse_categorical_accuracy: 0.8873 - mean_absolute_error: 4.4200\n",
      "Epoch 7/8\n",
      "235/235 - 1s - loss: 0.3046 - sparse_categorical_accuracy: 0.8922 - mean_absolute_error: 4.4200\n",
      "Epoch 8/8\n",
      "235/235 - 1s - loss: 0.2976 - sparse_categorical_accuracy: 0.8936 - mean_absolute_error: 4.4200\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit(train_images[..., tf.newaxis], train_labels, epochs=8, batch_size=256, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>sparse_categorical_accuracy</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.568350</td>\n",
       "      <td>0.800600</td>\n",
       "      <td>4.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.393926</td>\n",
       "      <td>0.860250</td>\n",
       "      <td>4.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.358524</td>\n",
       "      <td>0.873200</td>\n",
       "      <td>4.420001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.340509</td>\n",
       "      <td>0.878767</td>\n",
       "      <td>4.419999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.329038</td>\n",
       "      <td>0.882717</td>\n",
       "      <td>4.420001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  sparse_categorical_accuracy  mean_absolute_error\n",
       "0  0.568350                     0.800600             4.420000\n",
       "1  0.393926                     0.860250             4.420000\n",
       "2  0.358524                     0.873200             4.420001\n",
       "3  0.340509                     0.878767             4.419999\n",
       "4  0.329038                     0.882717             4.420001"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the history into a pandas DataFrame\n",
    "df = pd.DataFrame(history.history)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a plot for the loss\n",
    "loss_plot = df.plot(y='loss', title='Loss vs. Epochs', legend=False)\n",
    "loss_plot.set(xlabel='Epochs', ylabel='Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The evaluate and predict methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 2ms/step - loss: 0.3224 - sparse_categorical_accuracy: 0.8875 - mean_absolute_error: 4.4200\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy, test_mae = model.evaluate(test_images[..., tf.newaxis], test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32237496972084045 0.887499988079071 4.419997215270996\n"
     ]
    }
   ],
   "source": [
    "print(test_loss, test_accuracy, test_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Dress\n"
     ]
    }
   ],
   "source": [
    "# Choose a random test image\n",
    "random_idx = np.random.choice(test_images.shape[0])\n",
    "sample = test_images[random_idx]\n",
    "plt.imshow(sample)\n",
    "plt.show()\n",
    "print(f\"Label: {labels[test_labels[random_idx]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: Dress\n"
     ]
    }
   ],
   "source": [
    "# Get the model predictions\n",
    "predictions = model.predict(sample[tf.newaxis, ..., tf.newaxis])\n",
    "print(f\"Model prediction: {labels[np.argmax(predictions)]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
