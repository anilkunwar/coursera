{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Programming\n",
    "\n",
    "> In this post, we will learn how to compute value functions and optimal policies, assuming you have the MDP model. You will implement dynamic programming to compute value functions and optimal policies and understand the utility of dynamic programming for industrial applications and problems. Further, you will learn about Generalized Policy Iteration as a common template for constructing algorithms that maximize reward. For this weekâ€™s graded assessment, you will implement an efficient dynamic programming agent in a simulated industrial control problem. This is the summary of lecture \"Fundamentals of Reinforcement Learning\" from Coursera.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Chanseok Kang\n",
    "- categories: [Python, Coursera, Reinforcement_Learning]\n",
    "- image: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Evaluation vs. Control\n",
    "\n",
    "### Dynamic Programming Algorithm\n",
    "\n",
    "- Use the Bellman equations to define iterative algorithms for both policy evaluation and control\n",
    "\n",
    "Dynamic programming techniques can be used to solve both policy evaluation and control if we have access to the dynamics function ($p$)\n",
    "\n",
    "### Policy Evaluation\n",
    "\n",
    "Policy evaluation is the task of determining the state-value function($v_{\\pi}$) for particular policy ($\\pi$)\n",
    "\n",
    "$$ \\pi \\rightarrow v_{\\pi} $$\n",
    "\n",
    "Recall that \n",
    "\n",
    "$$ v_{\\pi}(s) \\doteq \\mathbb{E}_{\\pi} [G_t \\vert S_t = s] $$\n",
    "\n",
    "and return \n",
    "\n",
    "$$ G_t \\doteq \\sum_{k=0}^{\\infty} \\gamma^k R_{t+k+1} $$\n",
    "\n",
    "### Policy improvement (or Control)\n",
    "\n",
    "Policy improvement (or Control) is the task of improving a policy.\n",
    "\n",
    "> Note: the acronym of Policy Improvement is P.I, which is same for policy iteration that will be covered in later section. In here, we used Control.\n",
    "\n",
    "The goal of control task is to modify a policy to produce a new one which is strictly better. Moreover, we can try to improve the policy repeatedly to obtain a sequence of better and better policies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
