{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model subclassing and custom training loops\n",
    "\n",
    "> In the section, we're going to look at ways to build fully customizable deep learning models and layers, as well as custom training loops. This is the summary of lecture \"Customizing your model with Tensorflow 2\" from Coursera.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Chanseok Kang\n",
    "- categories: [Python, Coursera, Deep_Learning, Tensorflow]\n",
    "- image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow: v2.3.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (16, 10)\n",
    "print('Tensorflow: v' + tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model subclassing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "class MyModel(Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyModel, self).__init__(**kwargs)\n",
    "        self.dense = Dense(16)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "    \n",
    "my_model = MyModel(name='my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        super(MyModel, self).__init__(**kwargs)\n",
    "        self.dense1 = Dense(16, activation='sigmoid')\n",
    "        self.dense2 = Dense(num_classes, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        h = self.dense1(inputs)\n",
    "        return self.dense2(h)\n",
    "    \n",
    "my_model = MyModel(10, name='my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "class MyModel(Model):\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        super(MyModel, self).__init__(**kwargs)\n",
    "        self.dense1 = Dense(16, activation='sigmoid')\n",
    "        self.dropout = Dropout(0.5)\n",
    "        self.dense2 = Dense(num_classes, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        h = self.dense1(inputs)\n",
    "        h = self.dropout(h, training=training)\n",
    "        return self.dense2(h)\n",
    "    \n",
    "my_model = MyModel(12, name='my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a simple model using the model subclassing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Softmax, concatenate\n",
    "\n",
    "# Build the model\n",
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dense_1 = Dense(64, activation='relu')\n",
    "        self.dense_2 = Dense(10)\n",
    "        self.dense_3 = Dense(5)\n",
    "        self.softmax = Softmax()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.dense_1(inputs)\n",
    "        y1 = self.dense_2(inputs)\n",
    "        y2 = self.dense_3(y1)\n",
    "        concat = concatenate([x, y2])\n",
    "        return self.softmax(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              multiple                  704       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              multiple                  110       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              multiple                  55        \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            multiple                  0         \n",
      "=================================================================\n",
      "Total params: 869\n",
      "Trainable params: 869\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print the model summary\n",
    "model = MyModel()\n",
    "model(tf.random.uniform([1, 10]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom layers\n",
    "\n",
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class LinearMap(Layer):\n",
    "    def __init__(self, input_dim, units):\n",
    "        super(LinearMap, self).__init__()\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.w = tf.Variable(initial_value=w_init(shape=(input_dim, units)))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.08419785, 0.09032108]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer = LinearMap(3, 2)\n",
    "inputs = tf.ones((1, 3))\n",
    "linear_layer(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(3, 2) dtype=float32, numpy=\n",
       " array([[ 0.01177313,  0.02823724],\n",
       "        [ 0.01359553,  0.14853281],\n",
       "        [ 0.05882918, -0.08644897]], dtype=float32)>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearMap(Layer):\n",
    "    def __init__(self, input_dim, units):\n",
    "        super(LinearMap, self).__init__()\n",
    "        self.w = self.add_weight(shape=(input_dim, units), initializer='random_normal')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "    def __init__(self, hidden_units, outputs, **kwargs):\n",
    "        super(MyModel, self).__init__(**kwargs)\n",
    "        self.dense = Dense(hidden_units, activation='sigmoid')\n",
    "        self.linear = LinearMap(hidden_units, outputs)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        h = self.dense(inputs)\n",
    "        return self.linear(h)\n",
    "    \n",
    "my_model = MyModel(64, 12, name='my_custom_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLayer(Layer):\n",
    "    def __init__(self, units, input_dim):\n",
    "        super(MyLayer, self).__init__()\n",
    "        self.w = self.add_weight(shape=(input_dim, units),\n",
    "                                 initializer='random_normal')\n",
    "        self.b = self.add_weight(shape=(units,),\n",
    "                                 initializer='zeros')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "    \n",
    "dense_layer = MyLayer(3, 5)\n",
    "x = tf.ones((1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[-0.01389172,  0.04375058,  0.05022782]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(5, 3) dtype=float32, numpy=\n",
       " array([[-0.00786409, -0.14401236,  0.01724722],\n",
       "        [ 0.00915931,  0.0028276 , -0.00614739],\n",
       "        [ 0.00219261,  0.03717669, -0.00987066],\n",
       "        [-0.04463616,  0.06955143,  0.053882  ],\n",
       "        [ 0.02725661,  0.07820722, -0.00488336]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_layer.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify trainable weights\n",
    "class MyLayer(Layer):\n",
    "    def __init__(self, units, input_dim, trainable=True):\n",
    "        super(MyLayer, self).__init__()\n",
    "        self.w = self.add_weight(shape=(input_dim, units),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=trainable)\n",
    "        self.b = self.add_weight(shape=(units,),\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=trainable)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "    \n",
    "dense_layer = MyLayer(3, 5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable weights:  0\n",
      "non-trainable weights:  2\n"
     ]
    }
   ],
   "source": [
    "print('trainable weights: ', len(dense_layer.trainable_weights))\n",
    "print('non-trainable weights: ', len(dense_layer.non_trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom layer to accumulate means of output values\n",
    "class MyLayerMean(Layer):\n",
    "    def __init__(self, units, input_dim):\n",
    "        super(MyLayerMean, self).__init__()\n",
    "        self.w = self.add_weight(shape=(input_dim, units),\n",
    "                                 initializer='random_normal')\n",
    "        self.b = self.add_weight(shape=(units, ),\n",
    "                                 initializer='zeros')\n",
    "        self.sum_activation = tf.Variable(initial_value=tf.zeros((units, )),\n",
    "                                          trainable=False)\n",
    "        self.number_call = tf.Variable(initial_value=0, trainable=False)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        activations = tf.matmul(inputs, self.w) + self.b\n",
    "        self.sum_activation.assign_add(tf.reduce_sum(activations, axis=0))\n",
    "        self.number_call.assign_add(inputs.shape[0])\n",
    "        return activations, self.sum_activation / tf.cast(self.number_call, tf.float32)\n",
    "    \n",
    "dense_layer = MyLayerMean(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.11429557 0.11336175 0.2226719 ], shape=(3,), dtype=float32)\n",
      "tf.Tensor([0.11429557 0.11336175 0.2226719 ], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
    "print(activation_means)\n",
    "\n",
    "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
    "print(activation_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dropout layer as a custom layer\n",
    "class MyDropout(Layer):\n",
    "    def __init__(self, rate):\n",
    "        super(MyDropout, self).__init__()\n",
    "        self.rate = rate\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.nn.dropout(inputs, rate=self.rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement the custom layers into a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "    def __init__(self, units_1, input_dim_1, units_2, units_3):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.layer_1 = MyLayer(units_1, input_dim_1)\n",
    "        self.dropout_1 = MyDropout(0.5)\n",
    "        self.layer_2 = MyLayer(units_2, units_1)\n",
    "        self.dropout_2 = MyDropout(0.5)\n",
    "        self.layer_3 = MyLayer(units_3, units_2)\n",
    "        self.softmax = Softmax()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.layer_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.layer_3(x)\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 46), dtype=float32, numpy=\n",
       "array([[0.01505274, 0.00440967, 0.01186635, 0.01480463, 0.0052786 ,\n",
       "        0.06085607, 0.01963878, 0.01349788, 0.02153641, 0.01047028,\n",
       "        0.01190034, 0.09343456, 0.03930609, 0.01401323, 0.01148802,\n",
       "        0.01334272, 0.01465472, 0.01345948, 0.04295795, 0.01297635,\n",
       "        0.02177626, 0.03739497, 0.03552929, 0.0103055 , 0.00840054,\n",
       "        0.00410533, 0.03198026, 0.00627796, 0.04092092, 0.01596299,\n",
       "        0.01010012, 0.01192442, 0.00852652, 0.01432405, 0.01291983,\n",
       "        0.01505812, 0.01317638, 0.00892776, 0.02420245, 0.10391107,\n",
       "        0.02057562, 0.02086692, 0.02771564, 0.0150604 , 0.01293542,\n",
       "        0.02217644]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModel(64, 10000, 64, 46)\n",
    "model(tf.ones((1, 10000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_layer_2 (MyLayer)         multiple                  640064    \n",
      "_________________________________________________________________\n",
      "my_dropout (MyDropout)       multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_3 (MyLayer)         multiple                  4160      \n",
      "_________________________________________________________________\n",
      "my_dropout_1 (MyDropout)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_4 (MyLayer)         multiple                  2990      \n",
      "_________________________________________________________________\n",
      "softmax_1 (Softmax)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 647,214\n",
      "Trainable params: 647,214\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic differentiation\n",
    "\n",
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(2.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = x ** 2\n",
    "    grad = tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=4.0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-0.9364567>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([0, 1, 2, 3], dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = tf.reduce_mean(x ** 2)\n",
    "    z = tf.math.sin(y)\n",
    "    dz_dy = tape.gradient(z, y)\n",
    "    \n",
    "dz_dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-0.9364567>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([0, 1, 2, 3], dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = tf.reduce_mean(x ** 2)\n",
    "    z = tf.math.sin(y)\n",
    "    dz_dy, dz_dx = tape.gradient(z, [y, x])\n",
    "    \n",
    "dz_dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([-0.        , -0.46822834, -0.9364567 , -1.404685  ], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz_dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data from a noise contaminated linear model\n",
    "def makeNoisyData(m, b, n=20):\n",
    "    x = tf.random.uniform(shape=(n, ))\n",
    "    noise = tf.random.normal(shape=(len(x), ), stddev=0.1)\n",
    "    y = m * x + b + noise\n",
    "    return x, y\n",
    "\n",
    "X_train, y_train = makeNoisyData(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X_train, y_train, 'b.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a custom layer for the linear regression model\n",
    "class LinearLayer(Layer):\n",
    "    def __init__(self):\n",
    "        super(LinearLayer, self).__init__()\n",
    "        self.m = self.add_weight(shape=(1, ), initializer='random_normal')\n",
    "        self.b = self.add_weight(shape=(1, ), initializer='zeros')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.m * inputs + self.b\n",
    "    \n",
    "linear_regression = LinearLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([-0.00999793, -0.02673336, -0.01040294, -0.036666  , -0.0357274 ,\n",
       "       -0.03764858, -0.02298309, -0.00036403, -0.03614097, -0.04187095,\n",
       "       -0.05201402, -0.01837858, -0.03109264, -0.02035277, -0.01153002,\n",
       "       -0.03224227, -0.02266003, -0.03195651, -0.0477748 , -0.02514589],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([-0.05376218], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loss 6.4852614\n"
     ]
    }
   ],
   "source": [
    "def SquaredError(y_pred, y_true):\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true))\n",
    "\n",
    "starting_loss = SquaredError(linear_regression(X_train), y_train)\n",
    "print('Starting loss', starting_loss.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and plot the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Loss 6.4853\n",
      "Step 1, Loss 4.9384\n",
      "Step 2, Loss 3.7610\n",
      "Step 3, Loss 2.8649\n",
      "Step 4, Loss 2.1829\n",
      "Step 5, Loss 1.6639\n",
      "Step 6, Loss 1.2688\n",
      "Step 7, Loss 0.9681\n",
      "Step 8, Loss 0.7392\n",
      "Step 9, Loss 0.5650\n",
      "Step 10, Loss 0.4325\n",
      "Step 11, Loss 0.3316\n",
      "Step 12, Loss 0.2548\n",
      "Step 13, Loss 0.1963\n",
      "Step 14, Loss 0.1518\n",
      "Step 15, Loss 0.1180\n",
      "Step 16, Loss 0.0922\n",
      "Step 17, Loss 0.0726\n",
      "Step 18, Loss 0.0576\n",
      "Step 19, Loss 0.0463\n",
      "Step 20, Loss 0.0376\n",
      "Step 21, Loss 0.0310\n",
      "Step 22, Loss 0.0260\n",
      "Step 23, Loss 0.0222\n",
      "Step 24, Loss 0.0193\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.05\n",
    "steps = 25\n",
    "\n",
    "for i in range(steps):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = linear_regression(X_train)\n",
    "        loss = SquaredError(predictions, y_train)\n",
    "        \n",
    "    gradients = tape.gradient(loss, linear_regression.trainable_variables)\n",
    "    \n",
    "    linear_regression.m.assign_sub(learning_rate * gradients[0])\n",
    "    linear_regression.b.assign_sub(learning_rate * gradients[1])\n",
    "    \n",
    "    print('Step {}, Loss {:.4f}'.format(i, loss.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m: 1, trained m: [0.9889205]\n",
      "b: 2, trained b: [1.9128261]\n"
     ]
    }
   ],
   "source": [
    "print('m: {}, trained m: {}'.format(1, linear_regression.m.numpy()))\n",
    "print('b: {}, trained b: {}'.format(2, linear_regression.b.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X_train, y_train, 'b.')\n",
    "X_linear_regression = np.linspace(min(X_train), max(X_train), 50)\n",
    "plt.plot(X_linear_regression, linear_regression.m * X_linear_regression + linear_regression.b, 'r.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
