{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating names with recurrent neural networks\n",
    "\n",
    "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
    "\n",
    "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
    "\n",
    "It's dangerous to go alone, take these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.696201Z",
     "start_time": "2018-08-13T20:26:38.104103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import keras_utils\n",
    "import tqdm_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
    "\n",
    "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.701832Z",
     "start_time": "2018-08-13T20:26:42.697766Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_token = \" \"  # so that the network knows that we're generating a first token\n",
    "\n",
    "# this is the token for padding,\n",
    "# we will add fake pad token at the end of names \n",
    "# to make them of equal size for further batching\n",
    "pad_token = \"#\"\n",
    "\n",
    "with open(\"names\") as f:\n",
    "    names = f.read()[:-1].split('\\n')\n",
    "    names = [start_token + name for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.707885Z",
     "start_time": "2018-08-13T20:26:42.703302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 7944\n",
      " Abagael\n",
      " Claresta\n",
      " Glory\n",
      " Liliane\n",
      " Prissie\n",
      " Geeta\n",
      " Giovanne\n",
      " Piggy\n"
     ]
    }
   ],
   "source": [
    "print('number of samples:', len(names))\n",
    "for x in names[::1000]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.857411Z",
     "start_time": "2018-08-13T20:26:42.709371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 16\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLgJmZhlzETAzy9j/B8WHKERRkkO/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f950d2bf278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = max(map(len, names))\n",
    "print(\"max length:\", MAX_LENGTH)\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len, names)), bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing\n",
    "\n",
    "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.864592Z",
     "start_time": "2018-08-13T20:26:42.858725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens: 56\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE: all unique characters go here, padding included!\n",
    "tokens = set(c for n in names for c in n)\n",
    "tokens.add(pad_token)\n",
    "\n",
    "tokens = list(tokens)\n",
    "n_tokens = len(tokens)\n",
    "print ('n_tokens:', n_tokens)\n",
    "\n",
    "assert 50 < n_tokens < 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast everything from symbols into identifiers\n",
    "\n",
    "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
    "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
    "\n",
    "To create such dictionary, let's assign `token_to_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.870330Z",
     "start_time": "2018-08-13T20:26:42.866135Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_to_id = {s:i for i, s in enumerate(tokens)}### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
    "\n",
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.875943Z",
     "start_time": "2018-08-13T20:26:42.871834Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
    "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, names))\n",
    "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        name_ix = list(map(token_to_id.get, names[i]))\n",
    "        names_ix[i, :len(name_ix)] = name_ix\n",
    "\n",
    "    return names_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.883107Z",
     "start_time": "2018-08-13T20:26:42.877186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Abagael\n",
      " Glory\n",
      " Prissie\n",
      " Giovanne\n",
      "[[28  4 21  0 23  0 39 17 50]\n",
      " [28 44 17 48 15 54 50 50 50]\n",
      " [28  6 15 46 29 29 46 39 50]\n",
      " [28 44 46 48  8  0 47 47 39]]\n"
     ]
    }
   ],
   "source": [
    "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
    "print('\\n'.join(names[::2000]))\n",
    "print(to_matrix(names[::2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a recurrent neural network\n",
    "\n",
    "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
    "<img src=\"./rnn.png\" width=600>\n",
    "\n",
    "Since we're training a language model, there should also be:\n",
    "* An embedding layer that converts character id x_t to a vector.\n",
    "* An output layer that predicts probabilities of next phoneme based on h_t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.039419Z",
     "start_time": "2018-08-13T20:26:42.884581Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remember to reset your session if you change your graph!\n",
    "s = keras_utils.reset_tf_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.044903Z",
     "start_time": "2018-08-13T20:26:44.041084Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import concatenate, Dense, Embedding\n",
    "\n",
    "rnn_num_units = 64  # size of hidden state\n",
    "embedding_size = 16  # for characters\n",
    "\n",
    "# Let's create layers for our recurrent network\n",
    "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
    "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
    "\n",
    "# an embedding layer that converts character ids into embeddings\n",
    "embed_x = Embedding(n_tokens, embedding_size)\n",
    "\n",
    "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
    "get_h_next = Dense(rnn_num_units, activation='tanh')\n",
    "\n",
    "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
    "get_probas = Dense(n_tokens, activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate names character by character starting with `start_token`:\n",
    "\n",
    "<img src=\"./char-nn.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.053212Z",
     "start_time": "2018-08-13T20:26:44.048389Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_one_step(x_t, h_t):\n",
    "    \"\"\"\n",
    "    Recurrent neural network step that produces \n",
    "    probabilities for next token x_t+1 and next state h_t+1\n",
    "    given current input x_t and previous state h_t.\n",
    "    We'll call this method repeatedly to produce the whole sequence.\n",
    "    \n",
    "    You're supposed to \"apply\" above layers to produce new tensors.\n",
    "    Follow inline instructions to complete the function.\n",
    "    \"\"\"\n",
    "    # convert character id into embedding\n",
    "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
    "    \n",
    "    # concatenate x_t embedding and previous h_t state\n",
    "    x_and_h = concatenate([x_t_emb, h_t])\n",
    "    \n",
    "    # compute next state given x_and_h\n",
    "    h_next = get_h_next(x_and_h)\n",
    "    \n",
    "    # get probabilities for language model P(x_next|h_next)\n",
    "    output_probas = get_probas(h_next)\n",
    "    \n",
    "    return output_probas, h_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loop\n",
    "\n",
    "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
    "\n",
    "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.342948Z",
     "start_time": "2018-08-13T20:26:44.056136Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
    "batch_size = tf.shape(input_sequence)[0]\n",
    "\n",
    "predicted_probas = []\n",
    "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
    "\n",
    "for t in range(MAX_LENGTH):\n",
    "    x_t = input_sequence[:, t]  # column t\n",
    "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
    "    \n",
    "    h_prev = h_next\n",
    "    predicted_probas.append(probas_next)\n",
    "    \n",
    "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
    "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
    "\n",
    "# next to last token prediction is not needed\n",
    "predicted_probas = predicted_probas[:, :-1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loss and gradients\n",
    "\n",
    "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
    "\n",
    "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
    "\n",
    "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.354310Z",
     "start_time": "2018-08-13T20:26:44.344648Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatten predictions to [batch*time, n_tokens]\n",
    "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
    "\n",
    "# flatten answers (next tokens) and one-hot encode them\n",
    "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
    "\n",
    "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
    "\n",
    "For simplicity you can ignore this comment, it's up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:45.076642Z",
     "start_time": "2018-08-13T20:26:44.355594Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
    "# Mind that predictions are probabilities and NOT logits!\n",
    "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
    "loss = tf.reduce_mean(keras.losses.categorical_crossentropy(answers_matrix, predictions_matrix))\n",
    "\n",
    "optimize = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.322187Z",
     "start_time": "2018-08-13T20:26:45.078296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncUiDu1JKxaH/D26erixTYOV4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f93e19e2d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size = 32\n",
    "history = []\n",
    "\n",
    "for i in range(1000):\n",
    "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
    "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
    "    \n",
    "    history.append(loss_i)\n",
    "    \n",
    "    if (i + 1) % 100 == 0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history, label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: sampling\n",
    "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.341196Z",
     "start_time": "2018-08-13T20:26:55.323787Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_t = tf.placeholder(tf.int32, (1,))\n",
    "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
    "\n",
    "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
    "# We reuse all parameters thanks to functional API usage.\n",
    "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
    "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
    "next_probs, next_h = rnn_one_step(x_t, h_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.346422Z",
     "start_time": "2018-08-13T20:26:55.342659Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
    "    '''\n",
    "    This function generates text given a `seed_phrase` as a seed.\n",
    "    Remember to include start_token in seed phrase!\n",
    "    Parameter `max_length` is used to set the number of characters in prediction.\n",
    "    '''\n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    s.run(tf.assign(h_t, h_t.initial_value))\n",
    "    \n",
    "    # feed the seed phrase, if any\n",
    "    for ix in x_sequence[:-1]:\n",
    "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
    "    \n",
    "    # start generating\n",
    "    for _ in range(max_length-len(seed_phrase)):\n",
    "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
    "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:58.458115Z",
     "start_time": "2018-08-13T20:26:55.347900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Solel\n",
      " Btadgy\n",
      " Srrenna\n",
      " AlollerZ\n",
      " Masconi\n",
      " Qdarle\n",
      " Kals\n",
      " Tedanl\n",
      " Faily\n",
      " Abei\n"
     ]
    }
   ],
   "source": [
    "# without prefix\n",
    "for _ in range(10):\n",
    "    print(generate_sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:01.986726Z",
     "start_time": "2018-08-13T20:26:58.459810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trumpata\n",
      " Trumpalod\n",
      " Trump\n",
      " Trumpee\n",
      " Trumpa\n",
      " Trumpa\n",
      " TrumpniQ\n",
      " Trumporle\n",
      " Trumpas\n",
      " Trumpey\n"
     ]
    }
   ],
   "source": [
    "# with prefix conditioning\n",
    "for _ in range(10):\n",
    "    print(generate_sample(' Trump'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Coursera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:02.004926Z",
     "start_time": "2018-08-13T20:40:02.000821Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# token expires every 30 min\n",
    "COURSERA_TOKEN = \"MInTWGbPH0KEV98L\"\n",
    "COURSERA_EMAIL = \"kcsgoodboy@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:18.923357Z",
     "start_time": "2018-08-13T20:40:03.549343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be30b47ab4a48449145303296f9474f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submitted to Coursera platform. See results on assignment page!\n"
     ]
    }
   ],
   "source": [
    "from submit import submit_char_rnn\n",
    "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
    "submission = (history, samples)\n",
    "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try it out!\n",
    "\n",
    "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
    "\n",
    "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
    "\n",
    "* Novels/poems/songs of your favorite author\n",
    "* News titles/clickbait titles\n",
    "* Source code of Linux or Tensorflow\n",
    "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
    "* Melody in notes/chords format\n",
    "* IKEA catalog titles\n",
    "* Pokemon names\n",
    "* Cards from Magic, the Gathering / Hearthstone\n",
    "\n",
    "If you're willing to give it a try, here's what you wanna look at:\n",
    "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
    "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
    "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
    "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
    "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
    "\n",
    "__Good hunting!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bonus level: dynamic RNNs\n",
    "\n",
    "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
    "\n",
    "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
    "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
    "\n",
    "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.975354Z",
     "start_time": "2018-08-13T20:27:12.737529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM outputs for each step [batch,time,n_tokens]:\n",
      "(10, 50, 56)\n"
     ]
    }
   ],
   "source": [
    "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
    "    def call(self, input, state):\n",
    "        # from docs:\n",
    "        # Returns:\n",
    "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
    "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
    "        return rnn_one_step(input[:, 0], state)\n",
    "    \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return n_tokens\n",
    "    \n",
    "cell = CustomRNN(rnn_num_units)\n",
    "\n",
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "    \n",
    "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
    "\n",
    "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
    "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
    "\n",
    "You can also use any pre-implemented RNN cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.981697Z",
     "start_time": "2018-08-13T20:27:12.977590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tTimeFreqLSTMCell\tUGRNNCell\t"
     ]
    }
   ],
   "source": [
    "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
    "    if obj.endswith('Cell'):\n",
    "        print(obj, end=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:13.168207Z",
     "start_time": "2018-08-13T20:27:12.986884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM hidden state for each step [batch,time,rnn_num_units]:\n",
      "(10, 50, 64)\n"
     ]
    }
   ],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "\n",
    "inputs_embedded = embed_x(input_sequence)\n",
    "\n",
    "# standard cell returns hidden state as output!\n",
    "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
    "\n",
    "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
    "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
